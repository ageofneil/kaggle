{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911b3c76-0f8b-4a68-b911-c69b6151de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guide: https://www.tensorflow.org/decision_forests/tutorials/beginner_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ee0b96a-088e-4c0b-899a-605384c59bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard stack\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Visualization\n",
    "from pandas_profiling import ProfileReport\n",
    "#import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "try:\n",
    "    from wurlitzer import sys_pipes\n",
    "except:\n",
    "    from colabtools.googlelog import CaptureLog as sys_pipes\n",
    "\n",
    "# Scikit-learn packages\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# display\n",
    "from IPython.core.magic import register_line_magic\n",
    "from IPython.display import Javascript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85626ca8-048a-4e79-a98c-0df491bae731",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "95484130-439f-4ba4-afc1-8259b1dc8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"\"\n",
    "TEST_PATH = \"\"\n",
    "label = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7514a11-496b-4315-8acb-e9ffffa413ed",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d0d7e48a-10a6-45d2-8da7-284b82c7b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "submission = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "32c801b3-d173-41f4-9fdc-11ea83ff1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1aa163f9-456f-45b1-b5c9-7daf788dd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50331ffe-7c81-414c-b074-bc479c1a2f78",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf4ebb-e368-4ee7-a5c2-98118a73c7c0",
   "metadata": {},
   "source": [
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9577d59b-c99c-4048-a458-02b08c49a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f0d60674-e270-4c09-b33d-709b98eeeb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(to_drop,axis=1)\n",
    "test = test.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df3a18-02bb-43ef-9746-e616421dcd7f",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "79a7864c-02bc-4424-8d75-988e4b175f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpute_missing(dataset):\n",
    "    \"\"\" \n",
    "    Edit this to fix nulls. Default version replaces all int/float with 0\n",
    "    \"\"\"\n",
    "    for col in dataset.columns:\n",
    "        if dataset[col].dtype not in [str, object]:\n",
    "            dataset[col] = dataset[col].fillna(0)\n",
    "    return dataset\n",
    "\n",
    "train = inpute_missing(train)\n",
    "test = inpute_missing(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1c1c6-a67c-4074-96d0-1fe91992d8fd",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bf5236d2-9d79-4909-8809-1f225ab30ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_transforms(dataset):\n",
    "    \"\"\" \n",
    "    NLP tranforms here. Default, None...\n",
    "    \"\"\"\n",
    "    return dataset\n",
    "\n",
    "train = nlp_transforms(train)\n",
    "test = nlp_transforms(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f76e41-80bd-4c07-b92a-d240146172bd",
   "metadata": {},
   "source": [
    "### Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bf6c9512-669a-4af0-a02c-4c8130409f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_transforms(dataset):\n",
    "    \"\"\" \n",
    "    NLP tranforms here. Default, None...\n",
    "    \"\"\"\n",
    "    return dataset\n",
    "\n",
    "train = nlp_transforms(train)\n",
    "test = nlp_transforms(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b38732-28fb-420f-8884-cbdd1dbbd33c",
   "metadata": {},
   "source": [
    "# Split & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4e13b1f6-144e-4325-b8db-0486bfce3256",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-f77695888342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_dataframe_to_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_dataframe_to_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_dataframe_to_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_py_3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2174\u001b[0;31m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2175\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[1;32m   2176\u001b[0m                                               default_test_size=0.25)\n",
      "\u001b[0;32m~/anaconda3/envs/ds_py_3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(train)\n",
    "\n",
    "train_tf = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
    "test_tf = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
    "predictions = tfdf.keras.pd_dataframe_to_tf_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f182ddc-eb67-445f-b22e-f844a83841f0",
   "metadata": {},
   "source": [
    "# Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6d934-a8fd-4ae5-a650-d4a841f60f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'rf_default': tfdf.keras.RandomForestModel(),\n",
    "    'gbt_default': tfdf.keras.GradientBoostedTreesModel(),\n",
    "    #'gbt_tune1': tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\"),\n",
    "    }\n",
    "\n",
    "# Run a 10-folds cross-validation.\n",
    "accuraties_per_fold = []\n",
    "\n",
    "for key in models:\n",
    "    print(key)\n",
    "    for  fold_idx, (train_indices, test_indices) in enumerate(KFold(n_splits=10, shuffle=True, random_state=42).split(train)):\n",
    "\n",
    "        print(f\"Running fold {fold_idx+1}\")\n",
    "\n",
    "        # Extract the training and testing examples.\n",
    "        sub_train_df = train.iloc[train_indices]\n",
    "        sub_test_df = train.iloc[test_indices]\n",
    "\n",
    "        # Convert the examples into tensorflow datasets.\n",
    "        sub_train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(sub_train_df, label=label)\n",
    "        sub_test_df = tfdf.keras.pd_dataframe_to_tf_dataset(sub_test_df, label=label)\n",
    "\n",
    "        # Train the model.\n",
    "        models[key].compile(metrics=[\"BinaryCrossentropy\"])\n",
    "        models[key].fit(sub_train_ds, verbose=False)\n",
    "\n",
    "        # Evaluate the model.\n",
    "        evaluation = models[key].evaluate(sub_test_df, return_dict=True, verbose=False)\n",
    "        #print(f\"Evaluation {evaluation}\")\n",
    "\n",
    "        accuraties_per_fold.append(evaluation[\"binary_crossentropy\"])\n",
    "\n",
    "    print(f\"Cross-validated Score: {np.mean(accuraties_per_fold)} for model: \" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d3c7f9-cd24-4b63-ba9e-bc0e99696d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary\n",
    "#model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262708b-8a0e-4cd2-93d7-c10078266e1b",
   "metadata": {},
   "source": [
    "# Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f81c3-c27e-444f-87e0-f513f3df4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c50782f6-939c-4a87-b01d-976cec825df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_baselines\n",
      "401/401 [==============================] - 1s 1ms/step\n",
      "401/401 [==============================] - 1s 1ms/step\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.8455 - binary_crossentropy: 0.3519\n",
      "gbt_baseline\n",
      "401/401 [==============================] - 1s 1ms/step\n",
      "401/401 [==============================] - 0s 1ms/step\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.8513 - binary_crossentropy: 0.3450\n",
      "gbt_tunes_1\n",
      "401/401 [==============================] - 1s 1ms/step\n",
      "401/401 [==============================] - 0s 1ms/step\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.8536 - binary_crossentropy: 0.3432\n"
     ]
    }
   ],
   "source": [
    "# A more complex, but possibly, more accurate model.\n",
    "model = # ex: tfdf.keras.RandomForestModel()\n",
    "\n",
    "model.compile(metrics=[\"accuracy\",\"BinaryCrossentropy\"])\n",
    "model.fit(train_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f68290-d586-41b2-9d11-36dfac7eee12",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f5d57dfe-ab03-4505-a3d6-53569bd0bf5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-382c30864d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "scores = model.predict(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f61f1-951c-4893-9c1c-6673d9b1fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_py_3.8",
   "language": "python",
   "name": "ds_py_3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
